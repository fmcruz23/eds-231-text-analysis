---
title: 'Topic 7: Word Embeddings'
output: pdf_document 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This week's Rmd file here: <https://github.com/MaRo406/EDS_231-text-sentiment/blob/main/topic_7.Rmd>

```{r packages, include = FALSE}
library(here)
library(tidytext)
library(tidyverse)
library(widyr)
library(irlba) #singluar value decomposition
library(broom) # creating search_synonym function
library(textdata)
library(ggplot2)
library(dplyr) 

#https://semantle.com/
```

Today we are using climbing incident data from this repo: <https://github.com/ecaroom/climbing-accidents>. Some analysis (in Excel) on the data was written up into a Rock and Ice magazine article.

But I've constructed our data set (link below) by pulling a few key variables including the full text of each incident report.

```{r data,}
incidents_df<-read_csv("https://raw.githubusercontent.com/MaRo406/EDS_231-text-sentiment/825b159b6da4c7040ce8295b9eae2fbbe9991ffd/dat/climbing_report_text.csv")
```

First, let's calculate the unigram probabilities, how often we see each word in this corpus.

```{r unigrams}
unigram_probs <- incidents_df %>%
    unnest_tokens(word, Text) %>%
    anti_join(stop_words, by = 'word') %>%
    count(word, sort = TRUE) %>%
    mutate(p = n / sum(n)) 
unigram_probs 
```

Next, we need to know how often we find each word near each other word -- the skipgram probabilities. This is where we use the sliding window.

```{r}
skipgrams <- incidents_df %>%
    unnest_tokens(ngram, Text, token = "ngrams", n = 5) %>%
    mutate(ngramID = row_number()) %>% 
    tidyr::unite(skipgramID, ID, ngramID) %>%
    unnest_tokens(word, ngram) %>%
    anti_join(stop_words, by = 'word')

skipgrams
```

```{r}
#calculate probabilities
skipgram_probs <- skipgrams %>%
    pairwise_count(word, skipgramID, diag = TRUE, sort = TRUE) %>%
    mutate(p = n / sum(n))
```

Having all the skipgram windows lets us calculate how often words together occur within a window, relative to their total occurrences in the data. We do this using the point-wise mutual information (PMI). It's the logarithm of the probability of finding two words together, normalized for the probability of finding each of the words alone. PMI tells us which words occur together more often than expected based on how often they occurred on their own.

```{r norm-prob}
#normalize probabilities
normalized_prob <- skipgram_probs %>%
    filter(n > 20) %>%
    rename(word1 = item1, word2 = item2) %>%
    left_join(unigram_probs %>%
                  select(word1 = word, p1 = p),
              by = "word1") %>%
    left_join(unigram_probs %>%
                  select(word2 = word, p2 = p),
              by = "word2") %>%
    mutate(p_together = p / p1 / p2)

#Which words are most associated with "rope"?   
normalized_prob %>% 
    filter(word1 == "rope") %>%
    arrange(-p_together)
```

Now we convert to a matrix so we can use matrix factorization and reduce the dimensionality of the data.

```{r pmi}
pmi_matrix <- normalized_prob %>%
    mutate(pmi = log10(p_together)) %>%
    cast_sparse(word1, word2, pmi)    
 
#remove missing data
pmi_matrix@x[is.na(pmi_matrix@x)] <- 0
#run SVD using irlba() which is good for sparse matrices
pmi_svd <- irlba(pmi_matrix, 100, maxit = 500) #Reducing to 100 dimensions
#next we output the word vectors:
word_vectors <- pmi_svd$u
rownames(word_vectors) <- rownames(pmi_matrix)
```

```{r syn-function}
search_synonyms <- function(word_vectors, selected_vector) {
dat <- word_vectors %*% selected_vector
    
similarities <- dat %>%
        tibble(token = rownames(dat), similarity = dat[,1])

similarities %>%
       arrange(-similarity) %>%
        select(c(2,3))
}
```

```{r find-synonyms}
fall <- search_synonyms(word_vectors,word_vectors["fall",])
slip <- search_synonyms(word_vectors,word_vectors["slip",])
```

```{r plot-synonyms}
slip %>%
    mutate(selected = "slip") %>%
    bind_rows(fall %>%
                  mutate(selected = "fall")) %>%
    group_by(selected) %>%
    top_n(15, similarity) %>%
    ungroup %>%
    mutate(token = reorder(token, similarity)) %>%
    ggplot(aes(token, similarity, fill = selected)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~selected, scales = "free") +
    coord_flip() +
    theme(strip.text=element_text(hjust=0, size=12)) +
    scale_y_continuous(expand = c(0,0)) +
    labs(x = NULL, title = "What word vectors are most similar to slip or fall?")
         
```

```{r word-math}
snow_danger <- word_vectors["snow",] + word_vectors["danger",] 
search_synonyms(word_vectors, snow_danger)

no_snow_danger <- word_vectors["danger",] - word_vectors["snow",] 
search_synonyms(word_vectors, no_snow_danger)
```

# Assignment

Download a set of pretrained vectors, GloVe, and explore them. 

Grab data here:

<!-- download.file('https://nlp.stanford.edu/data/glove.6B.zip',destfile = 'glove.6B.zip')

<!--unzip('glove.6B.zip')

<!-- Use this file: 'glove.6B.300d.txt' -->

```{r, warning = FALSE}
# read in data 
library(data.table)
glove <- fread('glove.6B.300d.txt', header = FALSE) %>% 
  remove_rownames() %>% 
  column_to_rownames(var = "V1")

glove <- as.matrix(glove)
```


1.  Recreate the analyses in the last three chunks (find-synonyms, plot-synonyms, word-math) with the GloVe embeddings. How are they different from the embeddings created from the climbing accident data? Why do you think they are different?
```{r}
# find synonyms 

fall_2 <- search_synonyms(glove, glove["fall",])
slip_2 <- search_synonyms(glove, glove["slip",]) 

```

```{r}
# plot synonyms 

slip_2 %>%
    mutate(selected = "slip") %>%
    bind_rows(fall_2 %>%
                  mutate(selected = "fall")) %>%
    group_by(selected) %>%
    top_n(15, similarity) %>%
    ungroup %>%
    mutate(token = reorder(token, similarity)) %>%
    ggplot(aes(token, similarity, fill = selected)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~selected, scales = "free") +
    coord_flip() +
    theme(strip.text=element_text(hjust=0, size=12)) +
    scale_y_continuous(expand = c(0,0)) +
    labs(x = NULL, title = "What word vectors are most similar to slip or fall?")

```

```{r}
# word math 

snow_danger <- glove["snow",] + glove["danger",] 
search_synonyms(glove, snow_danger)

no_snow_danger <- word_vectors["danger",] - word_vectors["snow",] 
search_synonyms(word_vectors, no_snow_danger)

```


**The GloVe embeddings differ from the climbing data embeddings in that the words related to fall are much more generic or related to economics in some way (e.g., decline, drop, price, stocks), as opposed to being related in a climbing context (e.g., rock, ice avalanche, climber). The synonyms for slip from the GloVe dataset were very interesting beacuse many of them were related to the game of cricket (e.g., wicket, bowled, dravid, etc.). On the other hand, in the climbing context we saw synonyms of fall related to climbing (line, rope, etc.). Since the climbing words came from climbing incident reports it makes much more sense that these synonyms would be much more concentrated within the climbing topic specifically. Another thing to point out is that the similarity values and much larger for the GloVe words (ranging to above 30) as compared to the climbing words (all below 1). The word math results were more similar, both containing words related to cold, extreme weather and hazardous conditions.  **

2.  Run the classic word math equation, "king" - "man" = ?

```{r}
king_man <- glove["king",] - glove["man",] 
search_synonyms(glove, king_man)
```


3.  Think of three new word math equations. They can involve any words you'd like, whatever catches your interest.

```{r}
ultimate_frisbee <- glove["frisbee",] + glove["ultimate",] 
search_synonyms(glove, ultimate_frisbee)

#search_synonyms(glove, glove["frisbee",])
```

**I play ultimate frisbee so I wanted to see if any terms pertaining to this sport would come up. Although it is an up-and-coming sport, this word math equation very much showed how it is still an obscure sport in many ways. The results that came up were more related to other sports from volleyball to kickball, etc. and didn't have to do with ultimate frisbee at all. There were also generic sports-related terms like thrill and fitness, but words that are very related to ultimate frisbee, like disc, were much farther down on the list.**

```{r}
university_coffee <- glove["university",] + glove["coffee",] 
search_synonyms(glove, university_coffee)
```

**I thought this word math equation would be interesting because college students drink a lot of coffee. Many college-related words came up but so did things like tea and studies and student.**

```{r}
data_science <- glove["data",] + glove["science",] 
search_synonyms(glove, data_science)
```

**Most of the words that came up for this word math equation didn't surprise me since they are all pretty related to tech and computers more broadly.**


