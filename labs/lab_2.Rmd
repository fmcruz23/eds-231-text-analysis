---
title: "lab_2"
author: "Felicia Cruz"
date: "4/13/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
library(LexisNexisTools)
library(tidyr) #text analysis in R
library(lubridate) #working with date data
library(pdftools) #read in pdfs
library(tidytext)
library(sentimentr)
library(readr)
```


for the Froelich et al plot:
- group_by date 
- summarize mean sentiment for that day 
- plot x = day, y = sentiment 
```{r}

```


for the lab:

```{r}

my_files <- list.files(pattern = ".docx", path = here("labs", "data"),
                       full.names = TRUE, recursive = TRUE, ignore.case = TRUE)

dat <- lnt_read(my_files) #Object of class 'LNT output'

```


```{r}
meta_df <- dat@meta
articles_df <- dat@articles
paragraphs_df <- dat@paragraphs
```


```{r}
# use the full text from the articles
dat2<- data_frame(element_id = seq(1:length(meta_df$Headline)), Date = meta_df$Date, Headline = meta_df$Headline)

paragraphs_dat <- data_frame(element_id = paragraphs_df$Art_ID, Text  = paragraphs_df$Paragraph)


dat3 <- inner_join(dat2, paragraphs_dat, by = "element_id")

```

```{r}
nrc_sent <- get_sentiments('nrc') #requires downloading a large dataset via prompt
```

```{r}
text_words <- dat3  %>%
  unnest_tokens(output = word, input = Text, token = 'words') # take the paragraphs and unnest to get a column of individual words 
 
 sent_words <- text_words %>% 
  anti_join(stop_words, by = 'word') %>% # remove stop words
  inner_join(nrc_sent, by = 'word') # join and retain only sentiment words
```


for the emotions plot: 
- x = date 
- y axis is a scale to 100% 
- stacked bar chart for each day adding up to 100%
- or line graph with 8 lines
```{r}

```

